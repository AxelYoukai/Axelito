{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy    \n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero leemos el archivo PSE.csv de la carpeta local, que contendrá los términos que queremos quitar de las stop_words\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('PSE.csv')\n",
    "ArrX = np.array(df.iloc[:,0])\n",
    "ArrX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos cada elemento de la variable ArrX para quitarlo del Stop_words.\n",
    "#Se aplica tanto en minúscula como en mayúsucla para evitar errores.\n",
    "for e in ArrX:\n",
    "    nlp.vocab[e].is_stop = False\n",
    "    nlp.vocab[e.lower()].is_stop = False\n",
    "nlp.vocab[\"me\"].is_stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función lectura csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leer():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    dfc = pd.read_csv('comentarios-etiquetados_CC_UTF-8.csv',sep=',',encoding=\"utf-8\")\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para clasificación - Mappeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar(dfc):\n",
    "    import collections\n",
    "    doc=np.array(dfc.iloc[:, [4,6]])\n",
    "    categories=[]\n",
    "    # Words -> category\n",
    "    categories = {Cat: [cate[1] for cate in doc if cate[0]==Cat] for Cat, y in collections.Counter(dfc.iloc[:,4]).items() if y > 1}\n",
    "    del dfc\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función preprocesamiento general spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(categories):\n",
    "    from unidecode import unidecode\n",
    "    ListaA = []\n",
    "    #Procesamiento automático:\n",
    "    ListaA= {key: [nlp(unidecode(value)) for value in values] for (key, values) in categories.items()} #Se almacena cada comentario preprocesado.\n",
    "    #Se remueven stop_words, signos de puntuación\n",
    "    PreC1=[]\n",
    "    ListaB = []\n",
    "    for k in ListaA.keys():\n",
    "        del PreC1\n",
    "        PreC1 = []\n",
    "        for doc in ListaA[k]:\n",
    "            lemmas = [tok.lemma_.lower() for tok in doc if not tok.is_punct | tok.is_stop]\n",
    "            lexical_tokens = [t.lower() for t in lemmas if t.isalpha()]\n",
    "            Sentencias_Procesadas=' '.join(lexical_tokens)\n",
    "            PreC1.append(Sentencias_Procesadas)\n",
    "        ListaB[k]=PreC1\n",
    "    return ListaB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para extraer características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtraerCaracteristicas(Lista):\n",
    "    for k in Lista.keys():\n",
    "        for doc in Lista[k]:\n",
    "            print([token.lemma_ for token in e if token.pos_ == \"NOUN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función comparar características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompararCaracteristicas(CComentario, CExperto, Criterio):\n",
    "    base = len(CComentario)\n",
    "    Contenido = 0\n",
    "    porIncrustar = []\n",
    "    for e in CComentario:\n",
    "        if e.lower() != Criterio.lower():\n",
    "            for Caracteristica in CExperto:\n",
    "                if Caracteristica.lower() == e.lower():\n",
    "                    Contenido++\n",
    "                else:\n",
    "                    porIncrustar.append(e.lower())\n",
    "    if (Contenido/base * 100 >=70):\n",
    "        Analizar_Sentimiento()\n",
    "    else:\n",
    "        Incrustar(porIncrustar, Criterio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Incrustar(NCaracterísticas, Criterio):\n",
    "    #Es necesario otro tipo de preprocesamiento para otro modelo w2v\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
